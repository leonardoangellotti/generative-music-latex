
\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{listings}
\usepackage{xcolor}

% Definire un nuovo colore verde scuro
\definecolor{darkgreen}{rgb}{0,0.5,0}

\lstset{
    basicstyle=\ttfamily\small,  % Cambia \footnotesize con la dimensione desiderata (es. \small, \large)
    basicstyle=\ttfamily,
    keywordstyle=\color{blue},
    commentstyle=\color{darkgreen},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=10pt,
    backgroundcolor=\color{white},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)}
}

% Per il titolo
\title{Titolo della Tesi}
\author{Nome dell'Autore}
\date{Anno Accademico 2023/2024}

% Inizio del documento
\begin{document}

% Pagina del titolo
\begin{titlepage}
    \begin{center}
        \includegraphics[width=0.15\textwidth]{units_sigillo.png} 
        \vspace{1cm}
        
        \textsc{\LARGE Università degli studi di Trieste}\\[1.5cm]
        
        \textsc{\Large Dipartimento di Matematica e Geoscienze}\\[0.5cm]
        
        \textsc{\large Intelligenza Artificiale e Data Science}\\[0.5cm]
        
        \vspace{2cm}
        
        % Titolo
        \HRule \\[0.4cm]
        { \huge \bfseries Musica Genetica \\[0.4cm] }
        \HRule \\[1.5cm]
        
        \vspace{2cm}
        
        \begin{minipage}{0.4\textwidth}
            \begin{flushleft} \large
                \emph{Autore:}\\
                Leonardo Angellotti
            \end{flushleft}
        \end{minipage}
        \begin{minipage}{0.4\textwidth}
            \begin{flushright} \large
                \emph{Relatore:} \\
                Luca Manzoni
            \end{flushright}
        \end{minipage}
        
        \vfill
        
        {\large Anno Accademico 2023/2024}
        
    \end{center}
\end{titlepage}

\tableofcontents

\chapter{Introduzione}

Sebbene Stravinsky sia famoso per aver affermato: “i buoni compositori prendono in prestito e i grandi compositori rubano”, 

C’è una grande differenza tra “impossibile” e “difficile da immaginare”. Il primo riguarda questo; la seconda riguarda te!

"C'è un'idea, la base di una struttura interna, espansa e divisa in forme diverse o gruppi di suoni che cambiano costantemente in forma, direzione e velocità, attratti e respinti da varie forze. La forma del lavoro è una conseguenza di questa interazione."
- Edgard Varèse, (1939)

La parola 'Algoritmo' deriva dai concetti di algebra e aritmetica dei matematici del IX secolo d.C., dalle culture arabe e greche a quelle indiane. La Musica Algoritmica ha una storia altrettanto lunga nell'era pre-informatica, dai lavori 'processuali' di George Brecht (Drip Music, 1962), Stockhausen (Setz die Segel zur Sonn, 1970), Xenakis (Metastaseis, 1971) fino a George Lewis (Voyager), ecc.

Gli algoritmi di Intelligenza Artificiale (AI) sono una delle tecnologie più ampiamente utilizzate e potenti del ventunesimo secolo. Sebbene la definizione esatta di AI si sia costantemente evoluta dagli anni '50 di Alan Turing alle attuali architetture di Deep Learning come Alpha Go, un aumento dell'accessibilità ha portato a un'assimilazione più rapida di una vasta gamma di algoritmi AI nella nostra cultura. 
Nei campi creativi, l'AI viene utilizzata per generare sceneggiature di film (Spotlight di Ross Goodwin), ricette di cucina (Chef Watson di IBM), poesie (http://botpoet.com/), arte visiva (Portrait of Edmond Belamy, venduto per $432.500) ecc. 
C'è anche un'ondata di produzione massiva di opere d'arte AI utilizzando dataset open access e basi di codice open source come le Generative Adversarial Networks (GAN).

Tali modelli AI per attività creative sono attualmente agli inizi e seguono quasi esclusivamente il modello di imitare il dataset su cui sono addestrati. 

Nel campo della creazione musicale, tali modelli di generazione automatica della musica sono mirati alla produzione di massa di contenuti musicali. 
Questo ha portato a molti esempi di sistemi di musica generativa che producono musica come fosse un problema di ottimizzazione ben definito. 
I corali di Bach (Deep Bach), la Modellazione della Musica Popolare (Folk RNN) ecc. sono alcuni esempi di modelli altamente vincolati che acquisiscono rappresentazioni dei pattern su cui sono addestrati.

Modellare la musica è un problema difficile per due ragioni principali:

(a) Le gerarchie semantiche sono complesse, soggettive e operano su più scale temporali (dell'ordine di secondi a diversi minuti);

(b) Le rappresentazioni audio a tassi di campionamento dell'udito umano rendono le sequenze da modellare davvero lunghe, ovvero una tipica canzone di 4 minuti in qualità CD (44 kHz, 16-bit) ha oltre 10 milioni di timesteps.

Negli ultimi cinque anni sono stati fatti molti progressi nella modellazione della musica per sistemi generativi nelle sue rappresentazioni simboliche e d'onda. 
Magenta di Google (2016 - 2020), MuseNet di OpenAI (2019) e Jukebox (2020), Flow Machines di Sony CSL (2012), il Universal Music Translator di Facebook AI Research (2019) e Deep Composer di Amazon (2019)
sono alcuni degli sforzi delle grandi aziende tecnologiche che utilizzano risorse massicce come grandi server e ampi dataset. 

Sebbene ci sia molto interesse tra accademici e sviluppatori di software nel creare il prossimo set di strumenti creativi utilizzando l'AI per la creazione musicale, 
ciò non si è riflesso nell'assimilazione delle idee AI da parte dei musicisti di oggi. 
Solo un ristretto numero di musicisti, limitato ai programmatori, sta utilizzando questi strumenti basati su codice nel loro processo creativo.

Un'altra limitazione è l'incapacità di guidare e modificare i modelli AI per personalizzare l'output all'interno delle strutture disponibili. 
I metodi attuali sono rigidi e consentono solo una singola mappatura dai parametri di input alla musica generata, con l'architettura fissata al momento dell'addestramento. 

Un potenziale vantaggio degli algoritmi AI rispetto ad altri sistemi di musica computazionale che seguono un insieme di istruzioni è la capacità di interrogare regioni di rappresentazione con più o meno probabilità. 
Ciò consente paradigmi un costante flusso tra Exploitation e exploration. 

Questo genere di modelli possono quindi essere utilizzati per esplorare scelte creative meno probabili da parte degli artisti.

"Se hai un computer che elabora combinazioni casuali di note musicali, un essere umano che ha sufficiente intuizione e tempo potrebbe benissimo cogliere un'idea o due. 
Un artista dotato, d'altra parte, potrebbe ascoltare la stessa composizione casuale e uscirne con un'idea completamente nuova, una in gado di innescare una nuova forma di melodia."
- Margaret Boden (2016, intervista con IBM)

\section{Motivazioni dello studio}

sono bello

\section{Obiettivi della tesi}

simpatico 

\section{Struttura della tesi}

intelligente

\chapter{Nozioni di Base}

il magico mondo della musica

\chapter{Metodi di generazione}

\section{generazione melodia}

Quando si considera il problema della generazione della musica, la forma più semplice di esercizio che viene in mente è la composizione di melodie monofoniche senza accompagnamento.

Nella maggior parte dei sistemi di generazione di melodie, l'obiettivo è comporre melodie con caratteristiche simili allo stile scelto.

Questi sistemi dipendono da una fitness-function che valuta le sequenze generate.
Tale funzione di fitness è spesso basata sulla somiglianza con un determinato corpus, stile o brano, o dipende in generale dalle regole teoriche musicali.

Caratteristiche esemplificative includono la tonalità, gli intervalli e durate.

I primi tentativi di generare melodie con i computer risalgono al 1956, quando Pinkerton costruì un \textbf{modello markoviano di primo ordine} , il “Banal Tune-Maker”, basato su un corpus di 39 semplici filastrocche,
tuttavia il modello tendeva ad essere ripetitivo.

Un altro problema nell'uso delle catene di Markov risiedeva nel plagio, le melodie infatti tendevano ad essere toppo simili a quelle originali.

Il compromesso tra la composizione di brani simili a lavori esistenti, contro la necessità di doverne creare di nuovi e creativi, è difficile da ricercare. 
Stravinsky, celebre compositore Russo, ha affermato: “i buoni compositori copiano, i grandi compositori rubano”.
Riferendosi a quest'idea tuttavia le macchine non hanno ancora la capacità di distinguere tra il furto astuto e il plagio totale.

Con quest'intuizione è stata poi introdotta la variabile MaxOrder, ad indicare il massimo ordine di sottosequenze consentito in una sequenza generata, per limitare le ripetizioni eccessive di materiale.

Applicazioni di tali vincoli di controllo possono essere: la volontà che una sequenza sia globalmente ascendente o che segua invece un intorno di note arbitrario.

Davismoon ed Eccles (2010) sono stati alcuni dei primi ricercatori a inquadrare la generazione musicale come un problema di ottimizzazione combinatoria con un modello di Markov. 
Per valutare la musica generata, il loro sistema costruisce un secondo modello di Markov, riducendo poi al minimo la distanza euclidea tra il modello originale e il nuovo modello. 
Per risolvere questo problema di minimizzazione è stato utilizzato un processo di simulated-anealing.

Comporre una melodia monofonica può sembrare un compito semplice rispetto alla partitura di un'intera sinfonia. 
Tuttavia, le melodie sono più che semplici movimenti tra le note, normalmente possiedono una \textbf{struttura a lungo termine}. 
Negli ultimi anni, alcune ricerche hanno dimostrato l’efficacia dell’utilizzo di tecniche come il deep learning per rafforzare la struttura a lungo termine.

Un recente studio di Roig (2014) genera melodie, concatenando pattern ritmici e melodici, campionandole da un database. 
La selezione viene effettuata sulla base di regole musicali combinate ad un sistema probabilistico. 
Questo approccio consente al modello di generare melodie con una struttura più ampia, facendo sì che il pezzo abbia momenti di auto-somiglianza.

Horner e Goldberg (1991), pionieri nell'applicazione degli algoritmi genetici (GA) nella composizione musicale, affrontano il problema del "interpolazione tematica", ovvero la trasformazione di un pattern musicale iniziale in uno finale, durante una durata specificata. 
Per farlo hanno utilizzato un algoritmo genetico, un tipo di metaeuristica diventato popolare negli anni '70. 
Solitamente genera un insieme (chiamato popolazione) di soluzioni, e attraverso una combinazione (simile a quella genetica) ne genera di nuove.

Sebbene esista molto lavoro sulla generazione di accordi data una melodia, alcuni studi si concentrano viceversa, sulla generazione di una melodia che si adatti a una sequenza di accordi.

Moorer (1972), ad esempio, genera prima una sequenza di accordi, e poi una linea melodica su questa.
Le note della melodia sono limitate solo a quelle dell'accordo corrispondente in un dato momento. 
Ad ogni punto si decide, sulla base di un modello markoviano del secondo ordine, di invertire i frammenti melodici basati sull'accordo, oppure di copiarne da quello precedente.
Le brevi melodie risultanti tuttavia hanno un suono estraneo, ciò è legato al fatto che l'approccio melodico, non è quello utilizzato dagli esseri umani, infatti il sistema non discrimina le sequenze "non familiari".

\subsection{armonia}

L'armonia è definita da una relazione verticale tra note, che suonano contemporaneamente, e orizzontale, cioè la relazione delle note nel tempo, come le transizioni tra accordi.
Il sistema può essere valutato secondo criteri come, la somiglianza con un genere musicale, o con la musica di un particolare artista.
Il sistema deve generare sequenze riconoscibili nel genere target, ma non “sostanzialmente uguali”.

La maggior parte degli studi adotta approcci basati sul training-set per determinare possibili accordi per un dato segmento melodico, e per garantire una corretta transiizione tra questi.
Questi sistemi comunemente producono uno scheletro armonico, e utilizzano modelli predefiniti per creare trame ritmiche e arrangiamenti.

Lee e Jang (2004) hanno utilizzato il modello di Markov del primo ordine, integrato con programmazione dinamica, per determinare il pattern armonico di una melodia canticchiata dall'utente; 
le probabilità di transizione dalle note correnti vengono apprese da 150 canzoni. 

Simon (2008) ha adottato un approccio simile; allenando il proprio sistema su 298 brani di vari generi come jazz, rock, pop, blues e altri. 
Entrambi i sistemi vengono valutati tramite feedback soggettivo, cioè da un umano e non da una qualche fitness-function, derivanti da sessioni di ascolto. 
Uno svantaggio di questo approccio è che le sequenze di accordi generate tendono ad essere generiche e indistinte nello stile.

Steedman (1984) ha studiato il blues a 12 battute, definendo un piccolo insieme di regole, riuscendo a produrre progressioni di accordi tipiche dello stile.
Come notato nell'articolo, non c'è stato alcun tentativo esplicito di generare buone progressioni di accordi o di evitarne di cattive. 

\subsection{ritmo}

Nei sistemi di generazione musicale, il ritmo deriva spesso dalla durata intrinseca di ciascuna nota. 
In generale, esistono meno sistemi di generazione ritmica rispetto a sistemi melodici.

Tokui e Iba (2000) hanno proposto il sistema CONGA, che usa algoritmi genetici per produrre modelli ritmici, usando l'utente umano come funzione fitness.
Brevi frammenti di schemi ritmici formano gli elementi cromosomici nell'algoritmo; subendo poi trasformazioni come il crossover e mutazioni. 

Un algoritmo genetico è stato implementato anche da Ariza (2002), generando ritmiche derivanti da variazioni genetiche.
La funzione fitness è consistita nel calcolare la distanza tra il ritmo generato e l'originale, fornito dall'utente, attraverso differenti misure di distanza. 

\section{Algoritmo Genetico}

\subsection{musica evolutiva}

L'applicazione dei metodi EC ai compiti musicali ha cominciato ad emergere all'inizio degli anni '90.

Ci sono tre criteri fondamentali da considerare: l'ambito del problema, la rappresentazione individuale e la misura dell'idoneità. 

L’ambito del problema definisce esattamente quale tipo di “musica” si desidera sviluppare; si è intenzionati di creare melodie, armonizzazioni o progressioni di accordi? 

Che stile musicale desideri creare? 
Nella ricerca è fondamentale la codifica del dominio, e quindi i limiti o lo stile musicale, entro cui l'algoritmo ricerca. 

Nella rappresentazione individuale ci si chiede come rappresentare la musica: audio, spartiti stampati, messaggi MIDI (Musical Instrument Digital Interface)? 
comunemente, per una più facile gestione dei dati, si ricorre al formato MIDI, dove il genoma contiene valori di pitch e durate. 

Infine la questione della misura di idoneità: supponendo che due individui rappresentino brani musicali nel dominio desiderato, cosa rende uno “migliore” dell’altro? 

Uno dei vantaggi dell'applicazione dell'EC è aggiorna continuamente una popolazione di soluzioni, piuttosto che un individuo, in modo che le relazioni tra individui possano essere inserite nel processo di ricerca. 

Questo aspetto è utilizzato in numerosi studi, che mostrano l'intera popolazione finale per ricercare un risultato. 

\subsection{Prime applicazioni dell'EC alla musica}

Horner e Goldberg furono tra i primi ad applicare un algoritmo genetico al processo di composizione musicale considerando il problema della “transizione tematica”. 
In questo si considerava la trasformazione di una frase melodica in un'altra, ed i genomi rappresentavano la serie di transizioni necessarie. 
La fitness-function si misurava quanto bene il modello finale corrispondeva al modello desiderato. 
Il sistema tuttavia è stato utilizzato per creare transizioni piuttosto che creare effettivamente nuova musica. 

Indipendentemente dalla rappresentazione utilizzata, la valutazione della musica è spesso un compito soggettivo e, come tale, una misura di fitness affidabile e solida può essere difficile da definire. 
Molti dei primi ricercatori aggirarono questo problema impiegando l'uso di un giudice umano, e tali sistemi sono noti come \textbf{Interactive EC} (IEC). 

Una funzione di fitness basata sull’uomo era stata precedentemente utilizzata con successo nell’evoluzione delle immagini, ma gli autori hanno notato una differenza pratica: più immagini possono essere visualizzate contemporaneamente, e molto rapidamente, 
mentre la musica è un fenomeno temporale, e quindi tutti gli individui devono essere ascoltati in sequenza, uno dopo l'altro. 
Ciò si traduce in un costo molto elevato nell’utilizzo di un essere umano come funzione di fitness.

John Biles creò il noto sistema GenJam che utilizzava un GA per evolvere gli assoli jazz. 
GenJam ha utilizzato due popolazioni indipendenti: una per le misure di fitness e una per la generazione di sequenze. 
L’utente ha valutato queste frasi \textbf{in tempo reale} come “buone” o “cattive”. 
Il sistema ha quindi utilizzato l'intero aggregato di frasi e misure per costruire un assolo jazz. 

In studi successivi, addestrando una ANN a fungere da funzione di fitness, eliminando così la necessità dell'ascoltatore umano.
Tuttavia, in questo caso ha riscontrato che i risultati erano in qualche modo carenti e ha stabilito che gli esseri umani ascoltano e sperimentano la musica in modi complessi e sottili che non vengono catturati bene dai modelli statistici come le ANN. 

Studi hanno fatto uso di ANN come fitness-function. 
Gli autori hanno limitato il loro dominio, considerando solo armonie basate su tre accordi nella tonalità di Do maggiore, e creando solo melodie di quattro battute come durata. 
La composizione è stata poi suddivisa in “mattoni” costituiti da ritmo, melodia primaria e armonia. 
Per ogni blocco è stata utilizzato una algoritmo genetico per generare la popolazione, ed una ANN è stata addestrata, da esempi forniti dall'utente, per giudicare i genomi candidati.
Gli autori hanno riconosciuto che questa combinazione di GA e ANN potrebbe produrre delle pseudo composizioni, 
ma le limitazioni applicate al dominio di addestramento da parte dell'utente hanno limitato fortemente il modello.

Durante gli anni ’90 molti professionisti hanno applicato l’EC ad aspetti della generazione musicale, ma nessun metodo è risultato ideale rispetto ad altri. 

Le misure di fitness basate su un corpus musicale o su un insieme di regole musicali possono soffrire di pregiudizi. 
Gli esperimenti che utilizzano un corpus musicale per ricavare una misura di fitness saranno sempre limitati dal dominio scelto, limitando così il potenziale creativo del sistema. 
Tali misure guidano l’evoluzione, ma indipendentemente da quanto coinvolta o sfaccettata sia una data misura di fitness, è sicuramente \textbf{impossibile dire che questa sia la misura definitiva della musica}.

\section{L-System}

Gli L-system (o Lindenmayer system) sono un tipo di sistema formale utilizzato principalmente per modellare la crescita di piante e altri organismi. 
Sono stati introdotti da Aristid Lindenmayer nel 1968 e sono composti da un alfabeto di simboli che, usati come insieme di regole di produzione, vengono impiegati per generare stringhe, a loro volta contenenti altri simboli, applicando dunque un approccio ricorsivo.
È necessario un assioma (o stringa iniziale) da cui iniziare, e meccanismi per interpretare le stringhe generate come strutture geometriche o altre forme di output.

Nella generazione musicale, gli L-system possono essere usati per creare strutture musicali complesse e organizzate. Ecco come:

Alfabeto: I simboli dell'alfabeto possono rappresentare note musicali, durate, dinamiche, articolazioni, e altri elementi musicali.
Assioma: La stringa iniziale può essere una sequenza di note o eventi musicali.
Regole di produzione: Le regole descrivono come trasformare ogni simbolo in una nuova sequenza di simboli musicali.

Esempio di applicazione
Immaginiamo un semplice L-system musicale:

Alfabeto: {A, B}
Assioma: A
Regole di produzione: 
  A → AB
  B → A

In questo esempio:
1. Partiamo dall'assioma "A".
2. Applichiamo le regole:
   - A diventa AB.
   - AB diventa ABA.
   - ABA diventa ABAAB.
   e così via.

Ora, mappiamo i simboli alle note musicali:
- A = Do
- B = Re

La sequenza generata può essere interpretata come una melodia: Do, Do-Re, Do-Re-Do, Do-Re-Do-Do-Re, e così via.

Gli L-system così permettono di generare pattern musicali ricorsivi e auto-simili che possono essere sia prevedibili che ma anche variabili. 

Nel paper Growing music, Peter Worth e Susan Stepney, hanno sperimentato in modo più approfondito questo sistema.

La musica è essenzialmente sequenziale nel tempo: non vogliamo un'interpretazione ramificata nel tempo. 
Definiamo un rendering sequenziale: interpretare  come "stato corrente push/pop eccetto l'ora"; 
F come “suona una nota di durata 1”; 
una sequenza di n Fa come “suona una singola nota di durata n”. 
Quindi una nota viene interrotta da un cambiamento di altezza, da un nuovo ramo o dalla desinenza del ramo corrente. 
La resa sequenziale del sistema L "a foglia" di quarta generazione è ritmicamente interessante e ha senso melodicamente:

% Inserimento di un'immagine
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{/Users/leonardoangellotti/Desktop/tesi latex/immagini/immagine1} 
    \caption{Descrizione dell'immagine}
    \label{fig:immagine}
\end{figure}

Sebbene il rendering sequenziale produca risultati piacevoli, può essere migliorato per catturare una gerarchia schenkeriana di sfondo/piano intermedio/primo piano. 
Jonas [4] usa il termine “la fioritura della diminuzione” nel descrivere la forma della sonata. 
Ciò suggerisce un'interpretazione in cui si “sentono” solo le estremità della pianta (foglie, fiori). La zona centrale e lo sfondo (il fusto e i rami) non vengono effettivamente percepiti
Analisi schenkeriana: danno solo la struttura da cui appare il primo piano.
Nella nostra rappresentazione Schenkeriana, interpreta F come 'aumenta la durata della nota di una nota da un quarto', ± come 'muovi su/giù una nota nella scala scelta', [come 'premi lo stato corrente e imposta la durata della nota su 0', ] come ' suona la nota in base allo stato corrente e pop' e X come null.
In questa versione, la “foglia” ora suona come

% Inserimento di un'immagine
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{/Users/leonardoangellotti/Desktop/tesi latex/immagini/immagine2} 
    \caption{Descrizione dell'immagine}
    \label{fig:immagine}
\end{figure}

Nonostante non sembri rientrare in una struttura 4/4, questa melodia suona molto musicale, con una melodia piuttosto caratteristica, anche con un metronomo che batte in 4/4 dietro di essa.

Le piante sono tutte diverse: i sistemi L stocastici vengono utilizzati per generare piante dalla stessa
“famiglia” ma con dettagli diversi. Allo stesso modo una resa musicale dovrebbe generare a
varietà di brani nello stesso “stile”. Consideriamo il seguente semplice sistema L stocastico
(dove il pedice sulla freccia indica la probabilità che venga scelta la regola).

ω: FA 
p1: FA →1/3 FA[+F]FA[-FA]FA 
p2: FA →1/3 FA[+F]FA 
p3: FA →1/3 FA[-FA]FA

Le rappresentazioni schenkeriane di tre diverse produzioni di questo L-System stocastico (3 iterazioni di profondità) sono:

% Inserimento di un'immagine
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{/Users/leonardoangellotti/Desktop/tesi latex/immagini/immagine3} 
    \caption{Descrizione dell'immagine}
    \label{fig:immagine}
\end{figure}

Sembrano "casuali" ma ben strutturati e non eccessivamente complessi (come ci si aspetterebbe dalla natura abbastanza semplice delle regole). 
Suonano "simili" tra loro, ma abbastanza diversi da poter essere usati magari in punti diversi dello stesso brano musicale, o quando combinato.

5 Conclusioni e ulteriori lavori
Presentiamo due interpretazioni musicali che producono suoni piacevoli dai classici sistemi L "vegetali". 
Il rendering sequenziale è relativamente ingenuo, ma funziona bene. 
La resa schenkeriana si ispira ad un'analogia tra i concetti della teoria musicale di primo/medio/sottofondo e le componenti di una pianta, e produce brani molto piacevoli.
Questi esempi sono stati valutati solo fino a una profondità di 3 o 4 iterazioni. 
Sembra che ci siano informazioni sufficienti in un tipico sistema L per creare solo una breve melodia ed essere comunque interessante. 
Nelle derivazioni più lunghe, le melodie cominciano a diventare noiose: lo stesso pezzo di musica si ripete continuamente, anche se normalmente trasposto in qualche modo. 
I sistemi L stocastici possono aiutare, imponendo un qualche tipo di struttura sulla partitura ma dando melodie varie. 
I sistemi L sensibili al contesto sembrano offrire il miglior potenziale per creare brani musicali più lunghi, poiché parti identiche della corda in punti diversi possono crescere in modo diverso, quindi il pezzo può effettivamente “andare da qualche parte” anziché ripetere lo stesso schema.
Partire da grammatiche musicali e produrre da esse sistemi in L funziona bene musicalmente. 
Tuttavia, il tentativo di ottenere una grafica contemporaneamente gradevole partendo da una grammatica musicale ha avuto meno successo: la ramificazione necessaria alla grafica non è parte intrinseca della teoria musicale esistente, e non è chiaro come inserirla. Altro lavoro sullo schenkeriano la resa dal punto di vista della teoria musicale può essere preziosa qui.
L-System più potenti, come gli L-System parametrici, potrebbero essere utilizzati per generare musica più complessa e realistica. Una possibilità interessante è l'uso di sistemi L con input ambientali [8]. 
Questi sono stati sviluppati per modellare gli effetti ambientali sulla crescita delle piante (sole, ombra, ecc.), ma potrebbero essere applicabili alla generazione musicale, per consentire a due L-System di far crescere insieme la loro musica come diversi “strumenti” per reagire l’uno all’altro.

\chapter{Algoritmo genetico}

Viene ora introdotto un progetto di algoritmo genetico utile ad esemplificare fin quanto detto.

All'interno del progetto la funzione:

% Inserimento di un esempio di codice
\begin{lstlisting}[language=Python]
 
# Main function for running all helper functions and handling user input.
def genetic_algorithm(key, root, tempo, rythm):

\end{lstlisting}

scrive su disco 10 genotipi di sequenze di note, in formato MIDI, come risultato al dell'esecuzione dell'algoritmo genetico.
La funzione prende in input dall'utente
key: la scala utilizzata nella scelta delle note, può essere major o minor.
root: la nota che indica la tonalità della canzone, e sulla quale verrà costruita la scala (C, C#, D, D#, E, F, F#, G, G#, A, A#, B)
tempo: il numero di battiti al minuto (bpm), ovvero la velocità di esecuzione, della composizione
rythm: il ritmo della composizione, ovvero la durata delle note, a scelta tra quattro predefiniti (rock, jazz, dance, bossa nova)

all'interno della funzione troviamo

\begin{lstlisting}[language=Python]

    # Build the scale based on the root note and chosen scale type
    scale = buildScale(root, key)

\end{lstlisting}

Restituisce un array, dove ogni numero rappresenta il codice MIDI di ogni nota. l'array rappresenta la scala, maggiore o minore, costruita partendo dalla nota fondamentale scelta.

Viene eseguita poi l'evoluzione vera e propria, attraverso la crescita del genoma.

\subsection{Run-Evolution}

\begin{lstlisting}[language=Python]

    # Run the genetic algorithm to evolve a melody using the specified mutation rate and scale
    evolvedMelody = runEvolution(MUTATION_RATE, scale)

\end{lstlisting}

runEvolution implementa un algoritmo genetico che migliora in modo iterativo la popolazione di genomi musicali attraverso selezione, crossover e mutazione, l'esecuzione avviene finché non viene raggiunto un genoma con il punteggio MAX_FITNESS specificato.

Viene inizialmente creata un popolazione, inizializzata con metodo random. la popolazione è composta da 10 genomi. Ogni genoma è un elenco 2D di sequenze di note organizzate in 8 bar, ciascuna contenente 16 note, tutte scelte casualmente dalla scala specificata.

Il codice che segue rappresenta il cuore di un algoritmo genetico utilizzato in quest'occasione, e in generale.

\begin{lstlisting}[language=Python]

 # Iterate for a maximum number of generations
    for _ in range(MAX_GENERATIONS):

        # Sort the population based on fitness scores in descending order
        population = sorted(population, key=fitnessFunction, reverse=True)
        
        # Select the top 2 genomes (the fittest) to carry over to the next generation
        nextGeneration = population[:2]

        # Generate the rest of the next generation through crossover and mutation
        for _ in range(len(population) // 2 - 1):

            # Select two parent genomes based on their fitness
            parentA, parentB = selectParents(population)
            # Perform crossover to produce two child genomes
            childA, childB = multipointCrossover(parentA, parentB)
            # Mutate the child genomes and add them to the next generation
            nextGeneration += [mutateGenome(childA, mutationRate, scale), mutateGenome(childB, mutationRate, scale)]

        # Update the population with the new generation
        population = nextGeneration
        
\end{lstlisting}

Per un numero massimo di generazioni prefissato, vengono create popolazioni di genomi.
Successivamente alla prima inizializzazione randomica, viene applicata la Fitness-Function, che assegna ad ogni genoma un peso/punteggio basandosi sui propri criteri di valutazione (vedremo in seguito).
Nella successiva popolazione vengono mantenuti i primi due genomi con il punteggio più alto, mentre per i restanti 8 vengono selezionati di volta in volta due genitori, da cui attraverso un (multipoint) crossover danno luogo a due figli, i quali passano attraverso un ultima fase di mutazione.
I processi di crossover e mutazione sono definiti di "exploration", perché servono ad esplorare soluzioni che i due migliori genomi non sono riusciti ad ottenere.
Viceversa i due genomi mantenuti con il punteggio più alto, che si tramandano da una popolazione alla successiva, servono a garantire la migliore performance ad ogni generazione, qualora i genomi di exploration non diano risultati soddisfacenti.
Quando avviene che in una popolazione, i figli generati ottengano un punteggio superiore ai due migliori correnti, questi vengono dunque sostituiti.
Al termine del numero massimo di generazioni (prefissato, MAX_GENERATIONS), viene scritta su disco l'ultima popolazione costituita da 10 genomi.
Il migliore tra questi (con punteggio più alto) viene chiamato best_genome.mid.

\subsection*{fitness-function}

La fitness function calcola il punteggio finale ponderando e sommando i punteggi dei componenti per fluidità, ritmo e armonia, restituendo il risultato.

vengono inizializzati i pesi e i punteggi.

\begin{lstlisting}[language=Python]

 # Weights for the different fitness components
    smoothnessWeight = 15
    restWeight = 5
    harmonyWeight = 20

    # Initialize fitness scores
    smoothnessScore = 0
    restScore = 0
    harmonyScore = 0
    
\end{lstlisting}

l'harmonyscore riporta il punteggio di armonizzazione tra le note, ovvero come queste suonino "bene" tra loro.
Di seguito un dizionario in cui troviamo come chiave la distanza tra la nota corrente e la precedente, e come valore il punteggio assegnato a tale distanza armonica.

\begin{lstlisting}[language=Python]

    # Harmony intervals table for scoring harmony
    harmonyIntervalsTable = {
        0: -20, 1: 5, 2: 5, 3: 50, 4: 50, 5: 30, 6: -10, 7: 50, 8: 10, 9: 40, 10: -2, 11: -2, 12: 10,
        13: -5, 14: 5, 15: 5, 16: 50, 17: 50, 18: 30, 19: -10, 20: 50, 21: 10, 22: 40, 23: -2, 24: -2, 25: 10
    }

\end{lstlisting}

Ecco un'analisi della tabella:

- **Intervalli consonanti perfetti** (0, 7, 12, 19, 24 semitoni): Questi intervalli, che corrispondono alle ottave e quinte perfette (e le loro ripetizioni all'ottava superiore), hanno punteggi molto alti (50 o 10), indicando che sono molto armoniosi.
    - 0 (Unisono): -20 (interessante che l'unisono sia visto come negativo in questo sistema).
    - 7 (Quinta giusta): 50
    - 12 (Ottava giusta): 10
    - 19 (Unisono all'ottava superiore): -10
    - 24 (Due ottave giuste): 10

- **Intervalli consonanti maggiori** (4, 9, 16, 21 semitoni): Questi includono la terza maggiore e la sesta maggiore, che sono generalmente considerati molto armoniosi.
    - 4 (Terza maggiore): 50
    - 9 (Sesta maggiore): 40
    - 16 (Decima, terza maggiore all'ottava superiore): 50
    - 21 (Tredicesima, sesta maggiore all'ottava superiore): 10

- **Intervalli consonanti minori** (3, 8, 17, 22 semitoni): Questi includono la terza minore e la sesta minore.
    - 3 (Terza minore): 50
    - 8 (Sesta minore): 10
    - 17 (Decima minore): 50
    - 22 (Tredicesima minore): 40

- **Intervalli dissonanti** (1, 2, 6, 10, 11, 13, 23 semitoni): Questi includono la seconda minore, la settima minore e la settima maggiore, che sono considerati meno armoniosi o dissonanti.
    - 1 (Seconda minore): 5
    - 2 (Seconda maggiore): 5
    - 6 (Tritono): -10
    - 10 (Settima minore): -2
    - 11 (Settima maggiore): -2
    - 13 (Ottava aumentata): -5
    - 23 (Nona aumentata): -2
    
Calcolo del punteggio di fluidità (smoothnessScore):

Se la differenza tra le note (noteDifference) è 0 (unisono), il punteggio di fluidità viene diviso per 10, penalizzando fortemente la ripetizione della stessa nota.
Se la differenza è minore o uguale a 2 semitoni, aumenta il punteggio di fluidità di 1, incentivando piccoli movimenti tra le note.
Se la differenza è di 11 semitoni (quasi un'ottava), il punteggio di fluidità viene diviso per 2, penalizzando questo ampio intervallo.
Per altri intervalli, il punteggio di fluidità aumenta di 1 / noteDifference, favorendo movimenti più piccoli tra le note. 
Se noteDifference è 0, si evita la divisione per zero assegnando 0.
Aggiustamento ulteriore del punteggio di fluidità:

Se le note sono un'ottava più una seconda (o una nona) di distanza l'una dall'altra (±1 o ±2 semitoni dalla distanza di un'ottava), il punteggio di fluidità aumenta di 0.5. 
Questo premia movimenti specifici tra ottave con piccole differenze, che potrebbero essere considerati particolarmente musicali.
Il codice cerca dunque di bilanciare l'armonia (basata sugli intervalli predefiniti) e la fluidità (basata sulla distanza tra note consecutive) in una sequenza musicale, con vari meccanismi per favorire o penalizzare certi tipi di movimenti tra le note.

if note is None and prevNote is None:
    consecutiveRests += 1

Se entrambe note e prevNote sono None, significa che si è verificata una pausa consecutiva. Incrementa il contatore consecutiveRests.

if numRests * 10 <= len(flatten(genome)):
    restScore += 10

Se il numero di pause (numRests) moltiplicato per 10 è inferiore o uguale alla lunghezza della sequenza musicale piatta (flatten(genome)), aumenta il punteggio ritmico (restScore) di 10. 
Questo premia una quantità ragionevole di pause nel contesto della lunghezza totale del genoma musicale, suggerendo che alcune pause sono considerate musicalmente desiderabili.

if consecutiveRests:
    restScore -= (consecutiveRests * 10)

Se ci sono pause consecutive (consecutiveRests > 0), penalizza il punteggio ritmico diminuendo restScore di consecutiveRests * 10. 
Questo penalizza pesantemente le pause consecutive, suggerendo che una lunga serie di pause è considerata indesiderabile dal punto di vista ritmico.

fitness_weight_genome = (smoothnessScore * smoothnessWeight) + (restScore * restWeight) + (harmonyScore * harmonyWeight)

Il punteggio di fitness finale (fitness_weight_genome) è calcolato come la somma ponderata dei punteggi componenti.
Ogni punteggio componente (smoothnessScore, restScore, harmonyScore) viene moltiplicato per il rispettivo peso (smoothnessWeight, restWeight, harmonyWeight).
La somma dei prodotti risultanti rappresenta il punteggio di fitness finale del genoma.

I pesi (smoothnessWeight, restWeight, harmonyWeight) permettono di enfatizzare o de-enfatizzare specifici aspetti della valutazione a seconda degli obiettivi desiderati per la composizione musicale. 
Ad esempio, aumentando il peso della fluidità, si darà maggiore importanza alle transizioni tra le note, mentre aumentando il peso dell'armonia, si enfatizzerà la qualità armonica della melodia. 
Questo metodo di valutazione è utile in contesti come algoritmi genetici per la generazione di musica, dove è necessario valutare e selezionare sequenze musicali basate su criteri compositi.

\subsection{risultati}

Eseguiamo dunque il programma.
Sono riportati le opzioni scelte per una generazione musicale esemplificativa.

% Inserimento di un'immagine
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{/Users/leonardoangellotti/Desktop/università/terzo anno/tesi/MusicGeneticAlgorithm-main/genetic_music/final results rock/results/setting} 
    \caption{Descrizione dell'immagine}
    \label{fig:immagine}
\end{figure}

al termine dell'esecuzione vengono stampati i risultati dei punteggi ottenuti dalla fitness function, per i genomi di ogni popolazione.

% Inserimento di un'immagine
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{/Users/leonardoangellotti/Desktop/università/terzo anno/tesi/MusicGeneticAlgorithm-main/genetic_music/final results rock/results/scores} 
    \caption{Descrizione dell'immagine}
    \label{fig:immagine}
\end{figure}

Le linee che si mantengono costanti sono i punteggi dei primi due genomi (con punteggio più alto ad ogni generazione) che nell'algoritmo scelto vengono tramandati senza alcuna alterazione (crossover, mutation).
Quando "nasce" un nuovo genoma che si verifica avere un punteggio più altro dei primi due, questo fissa un nuovo livello di punteggio superiore ai precedenti, che viene mantenuto finché ciò non accade nuovamente.
Questa procedura garantisce un costante aumento del punteggio e un conseguente miglioramento tra le popolazioni.
La nuvola di punti che appaiono al di sotto, con punteggio inferiore, appartengono al set di genomi soggetti a crossover e mutazioni.

Al termine della procedura evolutiva, vengono stampati i 10 genomi appartenenti all'ultima popolazione.

% Inserimento di un'immagine
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{/Users/leonardoangellotti/Desktop/università/terzo anno/tesi/MusicGeneticAlgorithm-main/genetic_music/final results rock/results/MIDI} 
    \caption{Descrizione dell'immagine}
    \label{fig:immagine}
\end{figure}

La stampa rappresenta 10 file midi, dal migliore (numero 0) al "peggiore" (numero 9) secondo la nostra fitness-function.
Le note sono rappresentate dalle linee orizzontali che appaiono a diverse altezze di pitch, indicati nell'asse delle ordinate.
Le note sono sequenziali, appaiono dunque in momenti consecutivi, con diversa durata (dettata dal ritmo scelto dall'utente)
Si ricorda che l'algoritmo genera una sequenza monofonica, infatti non appare più di una nota contemporaneamente.

Le sequenze vengono salvate su disco. 
Il genoma migliore prende il nome di best_genome.mid, mentre ai restanti viene assegnato un numero in ordine decrescente in punteggio (genome_0.mid, ..., genome_8.mid).

Ad un primo ascolto di best_genome.mid, percepiamo un movimento coerente nella teoria, ordinato nel ritmo, ma non regolare nel tempo. 
Non viene percepita infatti alcuna vera struttura compositiva, questo perché la fitness function si è preoccupata di fare confronti solo tra una nota e la precedente, e non tra tutte le note della sequenza.
Non esiste dunque una vera struttura a lungo termine, una struttura narrativa, avente inizio svolgimento e fine, propria invece di qualsiasi genere musicale.
Non è presente nemmeno il classico schema delle canzoni pop: verso-ritornello-verso-ritornello-bridge-ritornello.

Per ovviare a questo difetto si procedere con un'operazione naive ma efficace:
Si decide di generare una nuova sequenza, chiamata repeated_melody.mid, la quale ripete per 4 volte le prime 3 bar prese dal best_genome.mid.
Il risultato risulta essere "ripetitivo" e dunque intrinsecamente più regolare, oltre a essere per il nostro orecchio più confortevole.

Abbiamo dunque ottenuto un risultato teorico "accettabile" e coerente. 
Possiamo ottenere di più nella pratica?
Si.
Importando il file midi (repeated_melody.mid) in una DAW (Digital Audio Workstation, in questo caso è stato utilizzato Ableton) possiamo apportare ulteriori modifiche.
Viene assegnata alla traccia lo strumento Grand Piano. 
Sue questa vengono applicate le seguenti opzioni

% Inserimento di un'immagine
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{/Users/leonardoangellotti/Desktop/università/terzo anno/tesi/MusicGeneticAlgorithm-main/genetic_music/final results rock/results/ableton_settings} 
    \caption{Descrizione dell'immagine}
    \label{fig:immagine}
\end{figure}

"MinorTim" permette di generare più note, ad una certa distanza in semitoni, partendo dalla nota corrente. 
Nel caso specifico un accordo minore.
Tuttavia un primo ascolto risulta essere poco piacevole, perché le note generate non considerano la scala di riferimento.
È necessario dunque usare lo strumento "Minor" per ancorare ogni nota in una posizione coerente.
Il risultato è decisamente più armonico, seppur tuttavia ancor troppo "piatto" con nessuna variazione nell'esecuzione.
Per far fronte a questa "freddezza" ed aumentare la dinamicità è possibile randomizzare, in modo automatico, i valori di Velocity nella sequenza per ciascuna nota.
Un nuovo ascolto ci ricorda un qualche compositore jazz, immerso nel suo fiume di sentimenti, vissuti istante per istante, 
ma che vuole comunque mantenere, per piacere della clientela, un ritmo e melodia regolari.

Per rendere il risultato ancor più gradevole, e musicalmente completo, possiamo aggiungere un elemento di percussioni, come una batteria.
Per il risultato ottenuto è stato utilizzato il plug-in Magenta (https://magenta.tensorflow.org/studio) sviluppato da Google e attualmente disponibile gratuitamente.
In particolare è stato utilizzata la funzione "Drumify", che data una sequenza di note, genera un secondo file MIDI in cui, similmente per il piano, vengono indicate le parti della batteria da percuotere (piatto, charleston, gran cassa, rullante).
In particolare, nel risultato finale, quest'ultima sequenza MIDI è stata processata dal Plugin SuperiorDrummer3 (https://www.toontrack.com/product/superior-drummer-3/?gad_source=1&gclid=Cj0KCQjws560BhCuARIsAHMqE0H2FsGI5sBj5JLtPNhhiKiLf9qMEccOntk8F9uc4_ZvSDPK5TCZZKUaAg1LEALw_wcB),
una libreria sofisticata che raccoglie suoni di batteria accurati.
Si vuole far notare, che l'algoritmo implementato in Drumify, si basa su una neural network, non è di tipo genetico come nel caso del nostro esempio, in grado dunque di cogliere e sviluppare una certa consequenzialità tra parti.

Infine, per le basse frequenze è stata aggiunta una semplice linea di basso, trasponendo la melodia due ottave inferiori, eliminando a mano, secondo il propio gusto, le note ridondanti, lasciando invece quelle fondamentali e di maggiore durata.

Il risultato finale, nello specifico, è "quasi" accettabile, considerando che per generarlo sono state necessarie poco più di 500 linee di codice (commenti inclusi) e qualche plugin dal mondo di internet.
Il tratto fondamentale risiede nel fatto che per ottenere questo file mp3, non abbiamo mai: né dovuto suonare un pianoforte, slappare un basso o ritmare una batteria a tempo.

Si possono sperimentare ulteriori modifiche, cambiando i pesi (smoothnessWeight, restWeight, harmonyWeight) o implementando un sistema nell'assegnazione della durata e velocity nelle note, ora affidate ad array con valori prefissati (rock, jazz, dance, bossa nova) e ad una scelta random rispettivamente.

\chapter{Conclusioni}

Negli ultimi decenni, la ricerca sulla generazione musicale ha compiuto enormi progressi nella generazione di aspetti ben definiti della musica come la melodia, l’armonia, il ritmo e il timbro. 
Modelli statistici all’avanguardia, tecniche di ottimizzazione avanzate, database digitali più grandi su cui addestrare i modelli e l’aumento della potenza di calcolo hanno portato alla produzione di sistemi migliori. 

Perché allora non utilizziamo sistemi di generazione musicale nella nostra vita quotidiana? 

L’indagine di cui sopra mostra che rimane un’importante sfida generale: quella di creare musica con una struttura a lungo termine.

La struttura a lungo termine, che spesso assume la forma di temi, motivi e schemi ricorrenti, è una parte essenziale di qualsiasi esperienza di ascolto musicale. In secondo luogo, gli sviluppi nel campo del deep learning mostrano che le reti neurali possono incorporare strutture di memoria durante l'apprendimento di dati sequenziali. 

Per rendere i sistemi musicali generati dal computer parte della nostra vita quotidiana, c’è bisogno di sistemi più “narrativi", in grado cioè di creare un inizio, sviluppo e conclusione nella musica. 

Sebbene ci siano recenti tentativi di generare musica con tensione [Farbood et al. 2007; Herremans e Chew 2016a], che sia applicata a colonne per videogiochi o che accompagnano film, c’è ancora margine di miglioramento per comprendere meglio la connessione tra musica ed emozione, 
in modo da integrare questa relazione cruciale nei sistemi di generazione musicale. 

Ciò potrebbe portare ad applicazioni pratiche nella vita reale, come la generazione di musica in tempo reale.

Sebbene le tecniche di apprendimento automatico possano essere estremamente utili in compiti come la già citata modellazione delle emozioni nella musica, di solito richiedono grandi quantità di dati. 

Pertanto, il settore ha riscontrato una continua necessità di ulteriori dati. 
Esiste un potenziale reale affinché il lavoro futuro si sposti verso sistemi intelligenti che non richiedano abbondanti quantità di dati, capaci di un ragionamento innato rispecchiando meglio il funzionamento della mente umana. 
Ciò risolverebbe anche la continua sfida di trovare un equilibrio tra la rigenerazione della musica esistente e i frammenti di questa senza ricadere nel plagio.

Una delle caratteristiche della musica generata dal computer che viene spesso trascurata è la difficoltà di esecuzione. 
Mentre un'applicazione potrebbe essere quella di adattare la nuova musica a un certo livello di abilità del musicista, esiste anche la possibilità di utilizzare la difficoltà di esecuzione rilevata/calcolata come misura di valutazione per la musica generata.

Rimane difficile, tuttavia, confrontare oggettivamente sistemi diversi poiché di solito accettano parametri di input diversi, generano aspetti musicali diversi, sono addestrati su stili diversi o non hanno esempi audio disponibili per il lettore. Inoltre, negli esperimenti di ascolto, l’effetto di mera esposizione [Zajonc 1968] farà sì che gli ascoltatori preferiscano i brani esistenti rispetto a quelli nuovi, poiché la familiarità provoca un maggiore godimento.

\appendix
\chapter{Appendice A}
\section{Dettagli aggiuntivi}

\chapter{Appendice B}
\section{Altro materiale supplementare}

% Esempio di citazione
Come descritto da Lamport \cite{latex}, e come discusso da Doe e Smith \cite{example_article}, i metodi utilizzati sono basati su...

% Bibliografia
\bibliographystyle{plain}
\bibliography{bibliografia}

\end{document}
